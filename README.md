# MNIST Digit Classification Using ANN ðŸ¤–ðŸ§ ðŸ‡¦ðŸ‡®ðŸ‘¾
_A Deep Learning Project Comparing Convoluted Neural Network (CNN) vs. Artificial Neural Network (ANN) Performance after being trained on the same dataset that undergone the same data cleaning and transformation_
<br><br><br>

## ðŸ“Œ Problem Statement
The MNIST dataset is a foundational benchmark in machine learning, consisting of 70,000 handwritten digit images (0-9). While modern deep learning models can achieve high accuracy on this dataset, it remains valuable for understanding fundamental neural network architectures and their comparative performance.

Key Challenges: <br>
âœ” Achieving high accuracy (>98%) with a simple ANN architecture<br>
âœ” Comparing performance between **Artificial Neural Networks (ANN)** and **Convolutional Neural Networks (CNN)** <br>
âœ” Understanding the trade-offs between model complexity and accuracy<br>
âœ” Preventing overfitting while maintaining generalization capability <br>
<br><br><br>

## ðŸŽ¯ Objectives
âœ” Build and train an ANN model for MNIST digit classification<br>
âœ” Compare performance between ANN and CNN architectures<br>
âœ” Analyze computational efficiency differences between ANN and CNN<br>
âœ” Achieve competitive accuracy (>98%) with a fully connected network<br>
âœ” Visualize model predictions to understand decision boundaries.<br>
<br><br><br>

## ðŸ“Š Dataset Overview
- Source: Classical MNIST dataset.
- Size: 70,000 grayscale images (28x28 pixels).
- Split: <br>
   âœ” 60,000 training images<br>
   âœ” 10,000 test images<br>
- Classes: 10 (digits 0-9). <br>
#### ðŸ”— Dataset Reference: [Yann LeCunâ€™s MNIST Page](http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz)
<br><br><br>

## ðŸ›  Skills & Technologies Used
### ðŸ“Œ Core Technologiess
- Python (Primary Language)
- Jupyter Notebook (Interactive Development)
- Git & GitHub (Version Control)


### ðŸ“Œ Key Libraries
- Deep Learning:	PyTorch
- Data Handling:	NumPy, Pandas
- Visualization:	Matplotlib, Seaborn
- Model Evaluation:	Scikit-learn (Metrics)


### ðŸ“Œ Model Architectures 
- Input Layer: Flattened 784-dimensional vector (28Ã—28 pixels)
- Hidden Layers: <br>
  Dense layers with ReLU activation<br>
  Dropout layers for regularization<br>
- Output Layer: 10-way softmax classification
### ðŸ“Œ Training Process
- Optimizer: Adam <br>
- Loss Function: Categorical Crossentropy <br>
- Metrics: Accuracy <br>
- Validation Split: 20% of training data <br>
- Early Stopping: Monitor validation loss <br>
<br><br><br>

## âš  Limitations & Challenges
1. Architectural Limitations: ANNs lack spatial awareness compared to CNNs
2. Parameter Efficiency: Fully connected layers require more parameters
3. Feature Extraction: Manual feature engineering may be needed for optimal performance
4. Computational Load: Memory requirements grow quickly with image size
<br><br><br>

## ðŸš€ Future Improvements
âœ… Hyperparameter Optimization: Systematic search for optimal architecture<br>
âœ… Advanced Regularization: Experiment with L1/L2 and dropout rates<br>
âœ… Feature Engineering: PCA or other dimensionality reduction techniques<br>
âœ… Hybrid Models: Combine ANN with simple convolutional layers<br>
âœ… Quantization: Optimize model for edge deployment<br>
<br><br><br>

## ðŸ“Š Performance Comparison (ANN vs CNN)

Metric  |   	ANN	  |   CNN
--------------------------
Test Accuracy | 98.2%	|  99.1%
-------------------------------
Training Time |	Faster 
|  Slower
-------------------------------
Parameters	| More |	Fewer
-------------------------------
Spatial Awareness |	No  |	Yes
-----
<br><br><br>




## ðŸ“œ License
This project is open-source under the MIT License. Contributions & feedback welcome!
<br><br><br>

 
 ## ðŸ“¬ Open to collaboration
 You can  create a pull request with detailed explanation if you would love to work more on this, or contact me through:
 - [Github](https://www.github.com/Abdulbasit4422).
 - [LinkedIn](https://www.linkedin.com/in/oyetunjiabdulbasitoyebamiji)
 - [X](https://mobile.x.com/Abdulbasitoyeb1)
 - [Facebook](https://www.facebook.com/abdulbasit.oyetunji?mibextid=ZbWKwL)
 - Gmail --> abdulbasitoyetunji88@gmail.com




